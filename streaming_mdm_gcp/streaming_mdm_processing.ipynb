{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Management (MDM) - Spanner Native Streaming Processing\n",
    "\n",
    "This notebook demonstrates a complete end-to-end streaming Master Data Management pipeline using Spanner's native capabilities:\n",
    "\n",
    "- **Golden Record Bootstrap**: Load existing golden records from BigQuery batch processing\n",
    "- **Spanner Infrastructure**: Set up minimal Spanner instance for real-time processing\n",
    "- **Data Migration**: Transfer golden records to Spanner for real-time matching\n",
    "- **Streaming Data Generation**: Create 100 new customer records for processing\n",
    "- **4-Way Real-time Matching**: Exact, fuzzy, vector, and business rules matching\n",
    "- **Synchronous Processing**: Sub-second processing with immediate feedback\n",
    "- **Golden Record Updates**: Apply survivorship rules and update master entities\n",
    "- **Live Performance Tracking**: Real-time metrics and Spanner transaction logging\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "This implementation follows the streaming processing path:\n",
    "1. **BigQuery Golden Records** ‚Üí **Spanner Migration**\n",
    "2. **Kafka-like Stream** ‚Üí **Real-time Standardization**\n",
    "3. **Spanner Vector Search** ‚Üí **4-Way Matching Engine**\n",
    "4. **Confidence Scoring** ‚Üí **AUTO_MERGE/CREATE_NEW Decisions**\n",
    "5. **Golden Record Updates** ‚Üí **Spanner Transaction Logging**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from batch_mdm_gcp.data_generator import MDMDataGenerator\n",
    "from batch_mdm_gcp.bigquery_utils import BigQueryMDMHelper\n",
    "from spanner_utils import SpannerMDMHelper\n",
    "from streaming_processor import StreamingMDMProcessor\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "sys.path.append('..')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION CONSTANTS - Centralized Settings\n",
    "# =============================================================================\n",
    "\n",
    "# GCP Configuration\n",
    "PROJECT_ID = \"your-project-id\"  # Replace with your GCP project ID\n",
    "DATASET_ID = \"mdm_demo\"  # BigQuery dataset (from batch processing)\n",
    "INSTANCE_ID = \"mdm-streaming-demo\"  # Spanner instance\n",
    "DATABASE_ID = \"mdm_streaming\"  # Spanner database\n",
    "LOCATION = \"US\"\n",
    "\n",
    "# Processing Configuration\n",
    "NUM_STREAMING_RECORDS = 100\n",
    "PROCESSING_DELAY_SEC = 0.1  # 10 record per second for demo\n",
    "TARGET_LATENCY_MS = 400  # Target processing time per record\n",
    "\n",
    "# Decision Thresholds\n",
    "AUTO_MERGE_THRESHOLD = 0.85\n",
    "CREATE_NEW_THRESHOLD = 0.65\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"  Target records: {NUM_STREAMING_RECORDS}\")\n",
    "print(f\"  Target latency: <{TARGET_LATENCY_MS}ms\")\n",
    "print(f\"  Auto-merge threshold: ‚â•{AUTO_MERGE_THRESHOLD}\")\n",
    "print(f\"  Create new threshold: <{CREATE_NEW_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize helpers\n",
    "try:\n",
    "    # BigQuery helper (for loading golden records)\n",
    "    bq_helper = BigQueryMDMHelper(PROJECT_ID, DATASET_ID)\n",
    "    print(f\"‚úÖ Connected to BigQuery project: {PROJECT_ID}\")\n",
    "    print(f\"üìä BigQuery dataset: {bq_helper.dataset_ref}\")\n",
    "\n",
    "    # Spanner helper (for streaming processing)\n",
    "    spanner_helper = SpannerMDMHelper(PROJECT_ID, INSTANCE_ID, DATABASE_ID)\n",
    "    print(f\"‚úÖ Connected to Spanner project: {PROJECT_ID}\")\n",
    "    print(f\"üóÉÔ∏è Spanner instance: {INSTANCE_ID}\")\n",
    "    print(f\"üóÉÔ∏è Spanner database: {DATABASE_ID}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting: {e}\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Set up Google Cloud authentication\")\n",
    "    print(\"2. Enabled BigQuery and Spanner APIs\")\n",
    "    print(\"3. Updated PROJECT_ID above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_statistics(result, action_counts, confidence_counts):\n",
    "    \"\"\"Update running statistics with current result.\"\"\"\n",
    "    action = result.get('action', 'ERROR')\n",
    "    confidence = result.get('confidence', 'LOW')\n",
    "\n",
    "    action_counts[action] = action_counts.get(action, 0) + 1\n",
    "    confidence_counts[confidence] = confidence_counts.get(confidence, 0) + 1\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spanner Infrastructure Setup\n",
    "\n",
    "Create minimal Spanner infrastructure for the streaming demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Setting up Spanner infrastructure...\")\n",
    "print(\"üí∞ Cost estimate: ~$65/month for 100 processing units (regional)\")\n",
    "print(\"‚ö†Ô∏è Remember to delete the instance after demo to avoid charges\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Create Spanner instance (minimal configuration)\n",
    "    spanner_helper.create_instance_if_needed(processing_units=100)\n",
    "\n",
    "    # Create database\n",
    "    spanner_helper.create_database_if_needed()\n",
    "\n",
    "    # Create schema (aligned with BigQuery golden_records)\n",
    "    spanner_helper.create_or_replace_schema()\n",
    "\n",
    "    print(\"\\n‚úÖ Spanner infrastructure ready!\")\n",
    "    print(f\"üìä Instance: {INSTANCE_ID} (100 processing units)\")\n",
    "    print(f\"üóÉÔ∏è Database: {DATABASE_ID}\")\n",
    "    print(f\"üìã Schema: golden_entities, match_results tables created\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error setting up Spanner infrastructure: {e}\")\n",
    "    print(\"Please check your GCP permissions and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Golden Records from BigQuery\n",
    "\n",
    "Bootstrap the streaming system with existing golden records from batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Loading golden records from BigQuery batch processing...\")\n",
    "\n",
    "try:\n",
    "    # Load golden records from BigQuery\n",
    "    golden_count = spanner_helper.load_golden_records_from_bigquery(bq_helper)\n",
    "\n",
    "    if golden_count > 0:\n",
    "        print(\n",
    "            f\"\\n‚úÖ Successfully migrated {golden_count} golden records to Spanner\")\n",
    "\n",
    "        # Verify the migration\n",
    "        current_count = spanner_helper.get_table_count(\"golden_entities\")\n",
    "        print(f\"üìä Current golden entities in Spanner: {current_count}\")\n",
    "\n",
    "        # Show sample records\n",
    "        sample_query = \"\"\"\n",
    "        SELECT entity_id, master_name, master_email, master_phone,\n",
    "               source_record_count, processing_path\n",
    "        FROM golden_entities\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "        sample_df = spanner_helper.execute_sql(sample_query)\n",
    "        if not sample_df.empty:\n",
    "            print(\"\\nüîç Sample Golden Records in Spanner:\")\n",
    "            sample_df.columns = ['entity_id', 'master_name',\n",
    "                                 'master_email', 'master_phone', 'source_count', 'path']\n",
    "            display(sample_df)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No golden records found in BigQuery\")\n",
    "        print(\"üí° Run the batch processing notebook first to create golden records\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading golden records: {e}\")\n",
    "    print(\"üí° Make sure you've run the batch processing notebook first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate New Streaming Data\n",
    "\n",
    "Create new customer records to simulate streaming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîÑ Generating {NUM_STREAMING_RECORDS} new streaming records...\")\n",
    "\n",
    "try:\n",
    "    # Generate new streaming data (different from batch data)\n",
    "    generator = MDMDataGenerator(num_unique_customers=NUM_STREAMING_RECORDS)\n",
    "    streaming_datasets = generator.generate_all_datasets()\n",
    "\n",
    "    # Combine all streaming records\n",
    "    all_streaming_records = []\n",
    "    for source, df in streaming_datasets.items():\n",
    "        for _, record in df.iterrows():\n",
    "            all_streaming_records.append(record.to_dict())\n",
    "\n",
    "    # Shuffle to simulate random streaming order\n",
    "    random.shuffle(all_streaming_records)\n",
    "\n",
    "    # Take exactly NUM_STREAMING_RECORDS\n",
    "    streaming_records = all_streaming_records[:NUM_STREAMING_RECORDS]\n",
    "\n",
    "    print(f\"\\nüìà Streaming Data Summary:\")\n",
    "    print(f\"  Total streaming records: {len(streaming_records)}\")\n",
    "\n",
    "    # Show source distribution\n",
    "    source_counts = {}\n",
    "    for record in streaming_records:\n",
    "        source = record.get('source_system', 'unknown')\n",
    "        source_counts[source] = source_counts.get(source, 0) + 1\n",
    "\n",
    "    for source, count in source_counts.items():\n",
    "        print(f\"  {source.upper()}: {count} records\")\n",
    "\n",
    "    print(f\"\\nüîç Sample Streaming Records:\")\n",
    "    sample_streaming = pd.DataFrame(streaming_records[:3])\n",
    "    display(sample_streaming[['record_id', 'full_name',\n",
    "            'email', 'phone', 'source_system']].head(3))\n",
    "\n",
    "    print(\"\\n‚úÖ Streaming data ready for processing!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error generating streaming data: {e}\")\n",
    "    streaming_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Streaming Processor\n",
    "\n",
    "Set up the 4-way matching processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Initializing 4-way streaming processor...\")\n",
    "\n",
    "try:\n",
    "    # Initialize the streaming processor\n",
    "    processor = StreamingMDMProcessor(spanner_helper)\n",
    "\n",
    "    print(\"\\nüìä Processor Configuration:\")\n",
    "    print(f\"  Matching strategies: 4 (exact, fuzzy, vector, business)\")\n",
    "    print(f\"  Strategy weights:\")\n",
    "    for strategy, weight in processor.weights.items():\n",
    "        print(f\"    {strategy}: {weight*100:.0f}%\")\n",
    "\n",
    "    print(f\"\\n‚öñÔ∏è Decision Thresholds:\")\n",
    "    print(f\"  Auto-merge: ‚â•{processor.auto_merge_threshold}\")\n",
    "    print(f\"  Create new: <{processor.create_new_threshold}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Streaming processor ready!\")\n",
    "    print(f\"üéØ Target: <{TARGET_LATENCY_MS}ms processing time per record\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing processor: {e}\")\n",
    "    processor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Processing Loop\n",
    "\n",
    "Process each record with sleep in between to simulate real-time pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"üöÄ Starting Streaming MDM Simulation ({NUM_STREAMING_RECORDS} records, per 100ms)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Validate prerequisites\n",
    "if not streaming_records:\n",
    "    print(\"‚ùå No streaming records available. Please run data generation first.\")\n",
    "elif not processor:\n",
    "    print(\"‚ùå Processor not initialized. Please run processor setup first.\")\n",
    "else:\n",
    "    # Track overall statistics\n",
    "    start_time = time.time()\n",
    "    total_processing_time = 0\n",
    "    action_counts = {}\n",
    "    confidence_counts = {}\n",
    "\n",
    "    # Process each record\n",
    "    for i, record in enumerate(streaming_records, 1):\n",
    "        record_start = time.time()\n",
    "\n",
    "        # Process the record with match details\n",
    "        result = processor.process_record(\n",
    "            record, i, NUM_STREAMING_RECORDS, include_match_details=True)\n",
    "\n",
    "        # Store match result in Spanner\n",
    "        try:\n",
    "            match_id = processor.store_match_result(record, result)\n",
    "            print(\n",
    "                f\"  üóÉÔ∏è ‚Üí Stored match result in Spanner (match_id: {match_id[:8]}...)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è ‚Üí Failed to store match result: {e}\")\n",
    "\n",
    "        # Update statistics\n",
    "        total_processing_time += result.get('processing_time_ms', 0)\n",
    "        update_statistics(result, action_counts, confidence_counts)\n",
    "\n",
    "        # Sleep to maintain processing pace\n",
    "        elapsed = time.time() - record_start\n",
    "        sleep_time = max(0, PROCESSING_DELAY_SEC - elapsed)\n",
    "        if sleep_time > 0:\n",
    "            print(f\"  ‚è±Ô∏è Next record in {sleep_time:.1f}s...\")\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "        print()  # Empty line for readability\n",
    "\n",
    "    # Calculate final statistics\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    print(\"üéâ Streaming Simulation Complete!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìä Processing Summary:\")\n",
    "    print(f\"  Records processed: {NUM_STREAMING_RECORDS}\")\n",
    "    print(f\"  Total time: {total_time:.1f} seconds\")\n",
    "    print(\n",
    "        f\"  Average processing time: {total_processing_time/NUM_STREAMING_RECORDS:.0f}ms\")\n",
    "    print(\n",
    "        f\"  Throughput: {NUM_STREAMING_RECORDS/total_time:.1f} records/second\")\n",
    "\n",
    "    print(f\"\\n‚öñÔ∏è Decision Distribution:\")\n",
    "    for action, count in action_counts.items():\n",
    "        percentage = (count / NUM_STREAMING_RECORDS) * 100\n",
    "        print(f\"  {action}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüéØ Confidence Distribution:\")\n",
    "    for confidence, count in confidence_counts.items():\n",
    "        percentage = (count / NUM_STREAMING_RECORDS) * 100\n",
    "        print(f\"  {confidence}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüìÅ Results stored in Spanner table: match_results\")\n",
    "    print(\"üí° Use Section 8 to analyze the results from Spanner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis and Visualization\n",
    "\n",
    "Analyze the streaming processing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Analyzing streaming processing results from Spanner...\")\n",
    "\n",
    "# Query transaction data from Spanner\n",
    "transactions_query = \"\"\"\n",
    "SELECT\n",
    "    record1_id, source1,\n",
    "    exact_score, fuzzy_score, vector_score, business_score,\n",
    "    combined_score, confidence_level, match_decision,\n",
    "    processing_time_ms, matched_at\n",
    "FROM match_results\n",
    "WHERE matched_at >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)\n",
    "ORDER BY matched_at DESC\n",
    "\"\"\"\n",
    "\n",
    "transactions_df = spanner_helper.execute_sql(transactions_query)\n",
    "\n",
    "# Rename columns for compatibility with existing analysis\n",
    "transactions_df.columns = [\n",
    "    'record_id', 'source_system',\n",
    "    'exact_score', 'fuzzy_score', 'vector_score', 'business_score',\n",
    "    'combined_score', 'confidence', 'action',\n",
    "    'processing_time_ms', 'matched_at'\n",
    "]\n",
    "\n",
    "# Add calculated columns for match counts\n",
    "transactions_df['exact_matches'] = (\n",
    "    transactions_df['exact_score'] > 0).astype(int)\n",
    "transactions_df['fuzzy_matches'] = (\n",
    "    transactions_df['fuzzy_score'] > 0).astype(int)\n",
    "transactions_df['vector_matches'] = (\n",
    "    transactions_df['vector_score'] > 0).astype(int)\n",
    "transactions_df['business_matches'] = (\n",
    "    transactions_df['business_score'] > 0).astype(int)\n",
    "\n",
    "\n",
    "# Performance analysis\n",
    "print(\"\\n‚ö° Performance Analysis:\")\n",
    "print(\n",
    "    f\"  Average processing time: {transactions_df['processing_time_ms'].mean():.0f}ms\")\n",
    "print(\n",
    "    f\"  Median processing time: {transactions_df['processing_time_ms'].median():.0f}ms\")\n",
    "print(\n",
    "    f\"  95th percentile: {transactions_df['processing_time_ms'].quantile(0.95):.0f}ms\")\n",
    "print(\n",
    "    f\"  Max processing time: {transactions_df['processing_time_ms'].max():.0f}ms\")\n",
    "\n",
    "# Matching effectiveness\n",
    "print(\"\\nüéØ Matching Effectiveness:\")\n",
    "print(\n",
    "    f\"  Average combined score: {transactions_df['combined_score'].mean():.3f}\")\n",
    "print(\n",
    "    f\"  Records with exact matches: {(transactions_df['exact_matches'] > 0).sum()}\")\n",
    "print(\n",
    "    f\"  Records with fuzzy matches: {(transactions_df['fuzzy_matches'] > 0).sum()}\")\n",
    "print(\n",
    "    f\"  Records with vector matches: {(transactions_df['vector_matches'] > 0).sum()}\")\n",
    "print(\n",
    "    f\"  Records with business matches: {(transactions_df['business_matches'] > 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "print(\"üìà Creating performance visualizations...\")\n",
    "\n",
    "# Processing time distribution\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Processing Time Distribution', 'Action Distribution',\n",
    "                    'Confidence Distribution', 'Combined Score Distribution'),\n",
    "    specs=[[{'type': 'histogram'}, {'type': 'pie'}],\n",
    "           [{'type': 'pie'}, {'type': 'histogram'}]]\n",
    ")\n",
    "\n",
    "# Processing time histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=transactions_df['processing_time_ms'], name='Processing Time (ms)'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Action distribution pie chart\n",
    "action_counts = transactions_df['action'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=action_counts.index,\n",
    "           values=action_counts.values, name='Actions'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Confidence distribution pie chart\n",
    "confidence_counts = transactions_df['confidence'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=confidence_counts.index,\n",
    "           values=confidence_counts.values, name='Confidence'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Combined score histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=transactions_df['combined_score'], name='Combined Score'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Streaming MDM Performance Analysis\", showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Visualizations created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy effectiveness analysis\n",
    "print(\"üéØ 4-Strategy Effectiveness Analysis:\")\n",
    "\n",
    "strategy_stats = pd.DataFrame({\n",
    "    'Strategy': ['Exact', 'Fuzzy', 'Vector', 'Business'],\n",
    "    'Records_with_Matches': [\n",
    "        (transactions_df['exact_matches'] > 0).sum(),\n",
    "        (transactions_df['fuzzy_matches'] > 0).sum(),\n",
    "        (transactions_df['vector_matches'] > 0).sum(),\n",
    "        (transactions_df['business_matches'] > 0).sum()\n",
    "    ],\n",
    "    'Average_Score': [\n",
    "        transactions_df['exact_score'].mean(),\n",
    "        transactions_df['fuzzy_score'].mean(),\n",
    "        transactions_df['vector_score'].mean(),\n",
    "        transactions_df['business_score'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(strategy_stats)\n",
    "\n",
    "# Strategy effectiveness chart\n",
    "fig = px.bar(\n",
    "    strategy_stats,\n",
    "    x='Strategy',\n",
    "    y='Records_with_Matches',\n",
    "    title='4-Strategy Matching Effectiveness',\n",
    "    labels={'Records_with_Matches': 'Records with Matches'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Strategy analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Golden Record Analysis\n",
    "\n",
    "Analyze the final state of golden records in Spanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèÜ Analyzing final golden record state...\")\n",
    "\n",
    "# Get final golden record count\n",
    "final_count = spanner_helper.get_table_count(\"golden_entities\")\n",
    "print(f\"\\nüìä Final golden entities count: {final_count}\")\n",
    "\n",
    "# Analyze processing paths\n",
    "path_query = \"\"\"\n",
    "SELECT processing_path, COUNT(*) as count\n",
    "FROM golden_entities\n",
    "GROUP BY processing_path\n",
    "ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "path_df = spanner_helper.execute_sql(path_query)\n",
    "if not path_df.empty:\n",
    "    path_df.columns = ['processing_path', 'count']\n",
    "    print(\"\\nüîÑ Processing Path Distribution:\")\n",
    "    display(path_df)\n",
    "\n",
    "# Analyze source record counts\n",
    "source_query = \"\"\"\n",
    "SELECT source_record_count, COUNT(*) as entities\n",
    "FROM golden_entities\n",
    "GROUP BY source_record_count\n",
    "ORDER BY source_record_count\n",
    "\"\"\"\n",
    "\n",
    "source_df = spanner_helper.execute_sql(source_query)\n",
    "if not source_df.empty:\n",
    "    source_df.columns = ['source_record_count', 'entities']\n",
    "    print(\"\\nüìà Source Record Count Distribution:\")\n",
    "    display(source_df)\n",
    "\n",
    "# Show sample updated records\n",
    "updated_query = \"\"\"\n",
    "SELECT entity_id, master_name, master_email, source_record_count,\n",
    "       processing_path, updated_at\n",
    "FROM golden_entities\n",
    "WHERE processing_path = 'stream'\n",
    "ORDER BY updated_at DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "updated_df = spanner_helper.execute_sql(updated_query)\n",
    "if not updated_df.empty:\n",
    "    updated_df.columns = ['entity_id', 'master_name',\n",
    "                          'master_email', 'source_count', 'path', 'updated_at']\n",
    "    print(\"\\nüîÑ Sample Updated Records (Streaming):\")\n",
    "    display(updated_df)\n",
    "\n",
    "print(\"\\n‚úÖ Golden record analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Metrics and Summary\n",
    "\n",
    "Calculate key performance indicators for the 4-strategy streaming MDM pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Calculating 4-Strategy Streaming MDM Performance Metrics...\")\n",
    "\n",
    "# Overall pipeline statistics\n",
    "initial_golden_count = golden_count if 'golden_count' in locals() else 0\n",
    "final_golden_count = spanner_helper.get_table_count(\"golden_entities\")\n",
    "new_entities_created = final_golden_count - initial_golden_count\n",
    "\n",
    "print(f\"\\nüìä Pipeline Statistics:\")\n",
    "print(f\"  Initial golden records (from BigQuery): {initial_golden_count}\")\n",
    "print(f\"  Streaming records processed: {NUM_STREAMING_RECORDS}\")\n",
    "print(f\"  Final golden records: {final_golden_count}\")\n",
    "print(f\"  Net new entities created: {new_entities_created}\")\n",
    "print(\n",
    "    f\"  Entity consolidation rate: {((NUM_STREAMING_RECORDS - new_entities_created) / NUM_STREAMING_RECORDS * 100):.1f}%\")\n",
    "\n",
    "# Performance metrics from transactions\n",
    "if 'transactions_df' in locals() and not transactions_df.empty:\n",
    "    print(f\"\\n‚ö° Performance Metrics:\")\n",
    "    print(\n",
    "        f\"  Average processing time: {transactions_df['processing_time_ms'].mean():.0f}ms\")\n",
    "    print(\n",
    "        f\"  Sub-second guarantee: {(transactions_df['processing_time_ms'] < 1000).sum()}/{len(transactions_df)} ({(transactions_df['processing_time_ms'] < 1000).mean()*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"  Target <400ms: {(transactions_df['processing_time_ms'] < 400).sum()}/{len(transactions_df)} ({(transactions_df['processing_time_ms'] < 400).mean()*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüéØ 4-Strategy Matching Results:\")\n",
    "    print(\n",
    "        f\"  Auto-merge rate: {action_counts.get('AUTO_MERGE', 0)}/{NUM_STREAMING_RECORDS} ({action_counts.get('AUTO_MERGE', 0)/NUM_STREAMING_RECORDS*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"  New entity rate: {action_counts.get('CREATE_NEW', 0)}/{NUM_STREAMING_RECORDS} ({action_counts.get('CREATE_NEW', 0)/NUM_STREAMING_RECORDS*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"  Average confidence score: {transactions_df['combined_score'].mean():.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Performance analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup and Cost Management\n",
    "\n",
    "Optional cleanup to avoid ongoing Spanner charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Demo Cleanup Options:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üí∞ Current Spanner instance cost: ~$65/month for {INSTANCE_ID}\")\n",
    "print(f\"üìä Processing units: 100 (regional)\")\n",
    "print(f\"üóÉÔ∏è Database: {DATABASE_ID}\")\n",
    "print()\n",
    "print(\"‚ö†Ô∏è To avoid ongoing charges, you can delete the Spanner instance:\")\n",
    "print(f\"   gcloud spanner instances delete {INSTANCE_ID} --quiet\")\n",
    "print()\n",
    "print(\"üí° The BigQuery golden records remain unchanged for future use.\")\n",
    "print(\"‚úÖ Streaming MDM demo completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
