{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Data Management (MDM) - BigQuery Native Batch Processing\n",
    "\n",
    "This notebook demonstrates a complete end-to-end Master Data Management pipeline using BigQuery's native capabilities:\n",
    "\n",
    "- **Data Generation**: Create realistic sample data with duplicates and variations\n",
    "- **Data Ingestion**: Load data into BigQuery from multiple sources\n",
    "- **Data Standardization**: Clean and normalize data using SQL\n",
    "- **Embedding Generation**: Use BigQuery ML with `gemini-embedding-001`\n",
    "- **Vector Indexing**: Create vector indexes for fast similarity search\n",
    "- **Entity Matching**: Implement exact, fuzzy, vector, business rules, and AI natural language matching\n",
    "- **Confidence Scoring**: Calculate match confidence and make decisions\n",
    "- **Golden Record Creation**: Generate master entities with survivorship rules\n",
    "- **Analysis & Visualization**: Analyze results and performance\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "This implementation follows the batch processing path from the MDM architecture:\n",
    "1. **Files/APIs/Databases** ‚Üí **BigQuery Raw Tables**\n",
    "2. **BigQuery Standardization** ‚Üí **BigQuery Staging**\n",
    "3. **BigQuery ML Embeddings** ‚Üí **BigQuery with Embeddings**\n",
    "4. **BigQuery Vector Search** ‚Üí **Unified Matching Engine**\n",
    "5. **Confidence Scoring** ‚Üí **Golden Record Creation**\n",
    "6. **Master Entities** ‚Üí **Analytics & Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bigquery_utils import (\n",
    "    BigQueryMDMHelper,\n",
    "    generate_standardization_sql,\n",
    "    generate_union_sql,\n",
    "    generate_embedding_sql,\n",
    "    generate_exact_matching_sql,\n",
    "    generate_fuzzy_matching_sql,\n",
    "    generate_vector_matching_sql,\n",
    "    generate_business_rules_sql,\n",
    "    generate_combined_scoring_sql,\n",
    "    generate_ai_natural_language_matching_sql\n",
    ")\n",
    "from data_generator import MDMDataGenerator\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from google.cloud import bigquery\n",
    "from google.auth import default\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PROJECT_ID = \"your-gcp-project-id\"  # Replace with your GCP project ID\n",
    "DATASET_ID = \"mdm_demo\"\n",
    "LOCATION = \"US\"\n",
    "\n",
    "# Initialize BigQuery helper\n",
    "try:\n",
    "    bq_helper = BigQueryMDMHelper(PROJECT_ID, DATASET_ID)\n",
    "    print(f\"‚úÖ Connected to BigQuery project: {PROJECT_ID}\")\n",
    "    print(f\"üìä Dataset: {bq_helper.dataset_ref}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to BigQuery: {e}\")\n",
    "    print(\"Please ensure you have:\")\n",
    "    print(\"1. Set up Google Cloud authentication\")\n",
    "    print(\"2. Enabled BigQuery API\")\n",
    "    print(\"3. Updated PROJECT_ID above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Data\n",
    "\n",
    "Create realistic customer data from multiple sources with intentional duplicates and variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "print(\"üîÑ Generating sample customer data...\")\n",
    "generator = MDMDataGenerator(num_unique_customers=120)\n",
    "datasets = generator.generate_all_datasets()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nüìà Dataset Summary:\")\n",
    "total_records = 0\n",
    "for source, df in datasets.items():\n",
    "    print(f\"  {source.upper()}: {len(df):,} records\")\n",
    "    total_records += len(df)\n",
    "\n",
    "print(f\"\\nüìä Total records: {total_records:,}\")\n",
    "print(f\"üë• Unique customers: {generator.num_unique_customers:,}\")\n",
    "print(\n",
    "    f\"üîÑ Duplication factor: {total_records / generator.num_unique_customers:.2f}x\")\n",
    "\n",
    "# Show sample records from each source\n",
    "print(\"\\nüîç Sample Records:\")\n",
    "for source, df in datasets.items():\n",
    "    print(f\"\\n{source.upper()} Sample:\")\n",
    "    display(df[['record_id', 'full_name', 'email',\n",
    "            'phone', 'address', 'source_system']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion to BigQuery\n",
    "\n",
    "Load the generated data into BigQuery raw tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "print(\"üîÑ Creating BigQuery dataset...\")\n",
    "bq_helper.create_dataset()\n",
    "\n",
    "# Load data to BigQuery\n",
    "print(\"\\nüîÑ Loading data to BigQuery...\")\n",
    "for source, df in datasets.items():\n",
    "    table_name = f\"raw_{source}_customers\"\n",
    "    print(f\"  Loading {source} data to {table_name}...\")\n",
    "    bq_helper.load_dataframe_to_table(df, table_name)\n",
    "\n",
    "print(\"\\n‚úÖ Data ingestion completed!\")\n",
    "\n",
    "# Verify data loading\n",
    "print(\"\\nüìä Table Information:\")\n",
    "for source in datasets.keys():\n",
    "    table_name = f\"raw_{source}_customers\"\n",
    "    info = bq_helper.get_table_info(table_name)\n",
    "    if info:\n",
    "        print(\n",
    "            f\"  {table_name}: {info['num_rows']:,} rows, {info['num_bytes']:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Standardization\n",
    "\n",
    "Clean and standardize data from all sources using BigQuery SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all raw data into a single table\n",
    "print(\"üîÑ Combining raw data from all sources...\")\n",
    "\n",
    "combine_sql = generate_union_sql(bq_helper.dataset_ref)\n",
    "\n",
    "bq_helper.execute_query(combine_sql)\n",
    "print(\"‚úÖ Raw data combined\")\n",
    "\n",
    "# Standardize the combined data\n",
    "print(\"\\nüîÑ Standardizing data...\")\n",
    "standardization_sql = generate_standardization_sql(\n",
    "    f\"{bq_helper.dataset_ref}.raw_customers_combined\",\n",
    "    f\"{bq_helper.dataset_ref}.customers_standardized\"\n",
    ")\n",
    "\n",
    "bq_helper.execute_query(standardization_sql)\n",
    "print(\"‚úÖ Data standardization completed\")\n",
    "\n",
    "# Show standardization results\n",
    "sample_query = f\"\"\"\n",
    "SELECT\n",
    "  record_id,\n",
    "  source_system,\n",
    "  full_name,\n",
    "  full_name_clean,\n",
    "  email,\n",
    "  email_clean,\n",
    "  phone,\n",
    "  phone_clean,\n",
    "  address,\n",
    "  address_clean\n",
    "FROM `{bq_helper.dataset_ref}.customers_standardized`\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "sample_df = bq_helper.execute_query(sample_query)\n",
    "print(\"\\nüîç Standardization Sample:\")\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedding Generation with BigQuery ML\n",
    "\n",
    "Generate embeddings using BigQuery's native ML.GENERATE_EMBEDDING function with the latest `gemini-embedding-001` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding model\n",
    "print(\"\\nüîÑ Creating embedding model...\")\n",
    "model_sql = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{bq_helper.dataset_ref}.embedding_model`\n",
    "REMOTE WITH CONNECTION DEFAULT\n",
    "OPTIONS(\n",
    "  ENDPOINT = 'gemini-embedding-001'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(model_sql)\n",
    "    print(\"‚úÖ Embedding model created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating model: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"1. You have necessary permissions\")\n",
    "    print(\"2. Vertex AI API is enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "print(\"üîÑ Generating embeddings...\")\n",
    "embedding_sql = generate_embedding_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_standardized\",\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\",\n",
    "    f\"{bq_helper.dataset_ref}.embedding_model\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(embedding_sql)\n",
    "    print(\"‚úÖ Embeddings generated successfully\")\n",
    "\n",
    "    # Check embedding dimensions\n",
    "    check_sql = f\"\"\"\n",
    "    SELECT\n",
    "      COUNT(*) as total_records,\n",
    "      COUNT(ml_generate_embedding_result) as records_with_embeddings,\n",
    "      ANY_VALUE(ARRAY_LENGTH(ml_generate_embedding_result)) AS embedding_dimension\n",
    "    FROM `{bq_helper.dataset_ref}.customers_with_embeddings`\n",
    "    WHERE ml_generate_embedding_result IS NOT NULL\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    result = bq_helper.execute_query(check_sql)\n",
    "    if not result.empty:\n",
    "        print(f\"üìä Embedding Statistics:\")\n",
    "        print(f\"  Total records: {result.iloc[0]['total_records']:,}\")\n",
    "        print(\n",
    "            f\"  Records with embeddings: {result.iloc[0]['records_with_embeddings']:,}\")\n",
    "        print(\n",
    "            f\"  Embedding dimension: {result.iloc[0]['embedding_dimension']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error generating embeddings: {e}\")\n",
    "    print(\"This might be due to:\")\n",
    "    print(\"1. Insufficient permissions\")\n",
    "    print(\"2. API quotas or limits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vector Index Creation\n",
    "\n",
    "Create vector indexes for efficient similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Vector index creation (with IVF) requires minimum 5,000 rows\n",
    "# For our sample dataset, we'll use direct vector search\n",
    "# which is actually more efficient for small datasets\n",
    "\n",
    "# Create vector index for fast similarity search (will results an error)\n",
    "print(\"üîÑ Creating vector index...\")\n",
    "\n",
    "vector_index_sql = f\"\"\"\n",
    "CREATE VECTOR INDEX IF NOT EXISTS customer_embedding_index\n",
    "ON `{bq_helper.dataset_ref}.customers_with_embeddings`(ml_generate_embedding_result)\n",
    "OPTIONS(\n",
    "  index_type = 'IVF',\n",
    "  distance_type = 'COSINE'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(vector_index_sql)\n",
    "    print(\"‚úÖ Vector index created successfully\")\n",
    "    print(\"üìà This will significantly speed up vector similarity searches\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Vector index creation failed: {e}\")\n",
    "    print(\"Vector search will still work but may be slower\")\n",
    "    print(\"Vector indexes require specific BigQuery editions and regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entity Matching\n",
    "\n",
    "Implement multiple matching strategies using BigQuery SQL:\n",
    "- **Exact Matching**: Direct field comparison\n",
    "- **Fuzzy Matching**: String similarity algorithms\n",
    "- **Vector Matching**: Semantic similarity using embeddings\n",
    "- **Business Rules**: Domain-specific logic\n",
    "- **AI Natural Language**: Direct AI comparison using Gemini 2.5 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Exact Matching\n",
    "print(\"üîÑ Running exact matching...\")\n",
    "exact_sql = generate_exact_matching_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\")\n",
    "bq_helper.execute_query(exact_sql)\n",
    "print(\"‚úÖ Exact matching completed\")\n",
    "\n",
    "# Check exact match results\n",
    "exact_count_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_exact_matches,\n",
    "  COUNT(CASE WHEN email_exact_score > 0 THEN 1 END) as email_matches,\n",
    "  COUNT(CASE WHEN phone_exact_score > 0 THEN 1 END) as phone_matches,\n",
    "  COUNT(CASE WHEN id_exact_score > 0 THEN 1 END) as id_matches\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_exact_matches`\n",
    "\"\"\"\n",
    "\n",
    "exact_stats = bq_helper.execute_query(exact_count_sql)\n",
    "print(\n",
    "    f\"üìä Exact Match Results: {exact_stats.iloc[0]['total_exact_matches']} total matches\")\n",
    "print(f\"  üìß Email matches: {exact_stats.iloc[0]['email_matches']}\")\n",
    "print(f\"  üìû Phone matches: {exact_stats.iloc[0]['phone_matches']}\")\n",
    "print(f\"  üÜî ID matches: {exact_stats.iloc[0]['id_matches']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Fuzzy Matching\n",
    "print(\"üîÑ Running fuzzy matching...\")\n",
    "fuzzy_sql = generate_fuzzy_matching_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\")\n",
    "bq_helper.execute_query(fuzzy_sql)\n",
    "print(\"‚úÖ Fuzzy matching completed\")\n",
    "\n",
    "# Check fuzzy match results\n",
    "fuzzy_count_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_fuzzy_matches,\n",
    "  AVG(name_fuzzy_score) as avg_name_score,\n",
    "  AVG(address_fuzzy_score) as avg_address_score,\n",
    "  AVG(fuzzy_overall_score) as avg_overall_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_fuzzy_matches`\n",
    "\"\"\"\n",
    "\n",
    "fuzzy_stats = bq_helper.execute_query(fuzzy_count_sql)\n",
    "print(\n",
    "    f\"üìä Fuzzy Match Results: {fuzzy_stats.iloc[0]['total_fuzzy_matches']} total matches\")\n",
    "print(f\"  üë§ Avg name score: {fuzzy_stats.iloc[0]['avg_name_score']:.3f}\")\n",
    "print(f\"  üè† Avg address score: {fuzzy_stats.iloc[0]['avg_address_score']:.3f}\")\n",
    "print(f\"  üìà Avg overall score: {fuzzy_stats.iloc[0]['avg_overall_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Vector Matching\n",
    "print(\"üîÑ Running vector similarity matching...\")\n",
    "vector_sql = generate_vector_matching_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\")\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(vector_sql)\n",
    "    print(\"‚úÖ Vector matching completed\")\n",
    "\n",
    "    # Check vector match results\n",
    "    vector_count_sql = f\"\"\"\n",
    "    SELECT\n",
    "      COUNT(*) as total_vector_matches,\n",
    "      AVG(vector_similarity_score) as avg_similarity,\n",
    "      MIN(vector_similarity_score) as min_similarity,\n",
    "      MAX(vector_similarity_score) as max_similarity\n",
    "    FROM `{bq_helper.dataset_ref}.customers_with_embeddings_vector_matches`\n",
    "    \"\"\"\n",
    "\n",
    "    vector_stats = bq_helper.execute_query(vector_count_sql)\n",
    "    print(\n",
    "        f\"üìä Vector Match Results: {vector_stats.iloc[0]['total_vector_matches']} total matches\")\n",
    "    print(f\"  üìà Avg similarity: {vector_stats.iloc[0]['avg_similarity']:.3f}\")\n",
    "    print(f\"  üìâ Min similarity: {vector_stats.iloc[0]['min_similarity']:.3f}\")\n",
    "    print(f\"  üìà Max similarity: {vector_stats.iloc[0]['max_similarity']:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Vector matching failed: {e}\")\n",
    "    print(\"This might be due to missing embeddings or vector index issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 Business Rules Matching\n",
    "print(\"üîÑ Running business rules matching...\")\n",
    "business_sql = generate_business_rules_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\")\n",
    "bq_helper.execute_query(business_sql)\n",
    "print(\"‚úÖ Business rules matching completed\")\n",
    "\n",
    "# Check business rules results\n",
    "business_count_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_business_matches,\n",
    "  COUNT(CASE WHEN same_company_score > 0 THEN 1 END) as company_matches,\n",
    "  COUNT(CASE WHEN same_location_score > 0 THEN 1 END) as location_matches,\n",
    "  COUNT(CASE WHEN age_compatibility_score > 0 THEN 1 END) as age_matches,\n",
    "  COUNT(CASE WHEN income_compatibility_score > 0 THEN 1 END) as income_matches\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_business_matches`\n",
    "\"\"\"\n",
    "\n",
    "business_stats = bq_helper.execute_query(business_count_sql)\n",
    "print(\n",
    "    f\"üìä Business Rules Results: {business_stats.iloc[0]['total_business_matches']} total matches\")\n",
    "print(f\"  üè¢ Company matches: {business_stats.iloc[0]['company_matches']}\")\n",
    "print(f\"  üìç Location matches: {business_stats.iloc[0]['location_matches']}\")\n",
    "print(f\"  üéÇ Age matches: {business_stats.iloc[0]['age_matches']}\")\n",
    "print(f\"  üí∞ Income matches: {business_stats.iloc[0]['income_matches']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gemini 2.5 Pro model\n",
    "print(\"\\nüîÑ Creating Gemini 2.5 Pro model...\")\n",
    "model_sql = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{bq_helper.dataset_ref}.gemini_25_pro_model`\n",
    "REMOTE WITH CONNECTION DEFAULT\n",
    "OPTIONS(\n",
    "  ENDPOINT = 'gemini-2.5-pro'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(model_sql)\n",
    "    print(\"‚úÖ Gemini model created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating model: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"1. You have necessary permissions\")\n",
    "    print(\"2. Vertex AI API is enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.5 AI Natural Language Matching\n",
    "print(\"ü§ñ Running AI natural language matching...\")\n",
    "\n",
    "# Generate AI natural language matching\n",
    "ai_sql = generate_ai_natural_language_matching_sql(\n",
    "    f\"{bq_helper.dataset_ref}.customers_with_embeddings\",\n",
    "    f\"{bq_helper.dataset_ref}.gemini_25_pro_model\"\n",
    ")\n",
    "bq_helper.execute_query(ai_sql)\n",
    "print(\"‚úÖ AI natural language matching completed\")\n",
    "\n",
    "# Check AI match results\n",
    "ai_count_sql = f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) as total_ai_matches,\n",
    "  AVG(ai_score) as avg_ai_score,\n",
    "  AVG(confidence) as avg_confidence,\n",
    "  MIN(ai_score) as min_ai_score,\n",
    "  MAX(ai_score) as max_ai_score\n",
    "FROM `{bq_helper.dataset_ref}.ai_natural_language_matches`\n",
    "\"\"\"\n",
    "\n",
    "ai_stats = bq_helper.execute_query(ai_count_sql)\n",
    "print(\n",
    "    f\"üìä AI Natural Language Results: {ai_stats.iloc[0]['total_ai_matches']} total matches\")\n",
    "print(f\"  ü§ñ Avg AI score: {ai_stats.iloc[0]['avg_ai_score']:.3f}\")\n",
    "print(f\"  üéØ Avg confidence: {ai_stats.iloc[0]['avg_confidence']:.3f}\")\n",
    "print(f\"  üìâ Min AI score: {ai_stats.iloc[0]['min_ai_score']:.3f}\")\n",
    "print(f\"  üìà Max AI score: {ai_stats.iloc[0]['max_ai_score']:.3f}\")\n",
    "\n",
    "# Show sample AI explanations\n",
    "sample_explanations_sql = f\"\"\"\n",
    "SELECT\n",
    "  ai_score,\n",
    "  confidence,\n",
    "  explanation\n",
    "FROM `{bq_helper.dataset_ref}.ai_natural_language_matches`\n",
    "ORDER BY ai_score DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "explanations = bq_helper.execute_query(sample_explanations_sql)\n",
    "print(\"\\nüîç Sample AI Explanations:\")\n",
    "for _, row in explanations.iterrows():\n",
    "    print(\n",
    "        f\"  Score: {row['ai_score']:.3f} | Confidence: {row['confidence']:.3f}\")\n",
    "    print(f\"  Explanation: {row['explanation']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Combined Scoring and Confidence Assessment\n",
    "\n",
    "Combine all 5 matching strategies with weighted scoring and calculate confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all matching scores (now with 5 strategies)\n",
    "print(\"üîÑ Combining match scores from 5 strategies...\")\n",
    "combined_sql = generate_combined_scoring_sql(\n",
    "    bq_helper.dataset_ref,\n",
    "    \"customers_with_embeddings\"\n",
    ")\n",
    "bq_helper.execute_query(combined_sql)\n",
    "print(\"‚úÖ Combined scoring completed\")\n",
    "\n",
    "# Analyze combined results\n",
    "analysis_sql = f\"\"\"\n",
    "SELECT\n",
    "  match_decision,\n",
    "  confidence_level,\n",
    "  COUNT(*) as count,\n",
    "  AVG(combined_score) as avg_score,\n",
    "  MIN(combined_score) as min_score,\n",
    "  MAX(combined_score) as max_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "GROUP BY match_decision, confidence_level\n",
    "ORDER BY avg_score DESC\n",
    "\"\"\"\n",
    "\n",
    "analysis_df = bq_helper.execute_query(analysis_sql)\n",
    "print(\"\\nüìä Match Decision Summary:\")\n",
    "display(analysis_df)\n",
    "\n",
    "# Show top matches\n",
    "top_matches_sql = f\"\"\"\n",
    "SELECT\n",
    "  record1_id,\n",
    "  record2_id,\n",
    "  source1,\n",
    "  source2,\n",
    "  exact_score,\n",
    "  fuzzy_score,\n",
    "  vector_score,\n",
    "  business_score,\n",
    "  ai_score,\n",
    "  combined_score,\n",
    "  match_decision,\n",
    "  confidence_level\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "ORDER BY combined_score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "top_matches_df = bq_helper.execute_query(top_matches_sql)\n",
    "print(\"\\nüèÜ Top 10 Matches (5-Strategy Analysis):\")\n",
    "display(top_matches_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Golden Record Creation\n",
    "\n",
    "Create master entities using survivorship rules and merge decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create golden records with survivorship rules\n",
    "print(\"üîÑ Creating golden records...\")\n",
    "\n",
    "golden_record_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{bq_helper.dataset_ref}.golden_records` AS\n",
    "WITH match_clusters AS (\n",
    "  -- Create clusters of matching records\n",
    "  SELECT\n",
    "    record1_id,\n",
    "    record2_id,\n",
    "    combined_score\n",
    "  FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "  WHERE match_decision IN ('auto_merge', 'human_review')\n",
    "),\n",
    "survivorship_rules AS (\n",
    "  -- Apply survivorship rules to select best values\n",
    "  SELECT\n",
    "    GENERATE_UUID() as master_id,\n",
    "    ARRAY_AGG(record_id) as source_record_ids,\n",
    "\n",
    "    -- Name: Most complete (longest)\n",
    "    ARRAY_AGG(full_name_clean ORDER BY LENGTH(full_name_clean) DESC LIMIT 1)[OFFSET(0)] as master_name,\n",
    "\n",
    "    -- Email: Most recent and complete\n",
    "    ARRAY_AGG(email_clean ORDER BY\n",
    "      CASE WHEN email_clean IS NOT NULL THEN 1 ELSE 0 END DESC,\n",
    "      processed_at DESC LIMIT 1)[OFFSET(0)] as master_email,\n",
    "\n",
    "    -- Phone: Most recent and complete\n",
    "    ARRAY_AGG(phone_clean ORDER BY\n",
    "      CASE WHEN phone_clean IS NOT NULL THEN 1 ELSE 0 END DESC,\n",
    "      processed_at DESC LIMIT 1)[OFFSET(0)] as master_phone,\n",
    "\n",
    "    -- Address: Most complete\n",
    "    ARRAY_AGG(address_clean ORDER BY LENGTH(address_clean) DESC LIMIT 1)[OFFSET(0)] as master_address,\n",
    "    ARRAY_AGG(city_clean ORDER BY LENGTH(city_clean) DESC LIMIT 1)[OFFSET(0)] as master_city,\n",
    "    ARRAY_AGG(state_clean ORDER BY LENGTH(state_clean) DESC LIMIT 1)[OFFSET(0)] as master_state,\n",
    "\n",
    "    -- Other fields: Most recent\n",
    "    ARRAY_AGG(company ORDER BY processed_at DESC LIMIT 1)[OFFSET(0)] as master_company,\n",
    "    ARRAY_AGG(annual_income ORDER BY processed_at DESC LIMIT 1)[OFFSET(0)] as master_income,\n",
    "    ARRAY_AGG(customer_segment ORDER BY processed_at DESC LIMIT 1)[OFFSET(0)] as master_segment,\n",
    "\n",
    "    -- Metadata\n",
    "    COUNT(*) as source_record_count,\n",
    "    ARRAY_AGG(DISTINCT source_system) as source_systems,\n",
    "    MIN(registration_date) as first_seen,\n",
    "    MAX(last_activity_date) as last_activity,\n",
    "    CURRENT_TIMESTAMP() as created_at\n",
    "\n",
    "  FROM `{bq_helper.dataset_ref}.customers_with_embeddings` c\n",
    "  WHERE record_id IN (\n",
    "    SELECT DISTINCT record1_id FROM match_clusters\n",
    "    UNION DISTINCT\n",
    "    SELECT DISTINCT record2_id FROM match_clusters\n",
    "  )\n",
    "  GROUP BY 1  -- Group by some clustering logic (simplified)\n",
    ")\n",
    "SELECT * FROM survivorship_rules\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    bq_helper.execute_query(golden_record_sql)\n",
    "    print(\"‚úÖ Golden records created successfully\")\n",
    "\n",
    "    # Check golden record statistics\n",
    "    golden_stats_sql = f\"\"\"\n",
    "    SELECT\n",
    "      COUNT(*) as total_golden_records,\n",
    "      AVG(source_record_count) as avg_sources_per_record,\n",
    "      MAX(source_record_count) as max_sources_per_record\n",
    "    FROM `{bq_helper.dataset_ref}.golden_records`\n",
    "    \"\"\"\n",
    "\n",
    "    golden_stats = bq_helper.execute_query(golden_stats_sql)\n",
    "    print(f\"üìä Golden Record Statistics:\")\n",
    "    print(\n",
    "        f\"  Total golden records: {golden_stats.iloc[0]['total_golden_records']}\")\n",
    "    print(\n",
    "        f\"  Avg sources per record: {golden_stats.iloc[0]['avg_sources_per_record']:.2f}\")\n",
    "    print(\n",
    "        f\"  Max sources per record: {golden_stats.iloc[0]['max_sources_per_record']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating golden records: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analysis and Visualization\n",
    "\n",
    "Analyze the MDM pipeline results and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive analysis\n",
    "print(\"üìä Analyzing MDM Pipeline Results...\")\n",
    "\n",
    "# Get overall statistics\n",
    "overall_stats_sql = f\"\"\"\n",
    "WITH stats AS (\n",
    "  SELECT\n",
    "    'Raw Records' as stage,\n",
    "    COUNT(*) as record_count\n",
    "  FROM `{bq_helper.dataset_ref}.raw_customers_combined`\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  SELECT\n",
    "    'Standardized Records' as stage,\n",
    "    COUNT(*) as record_count\n",
    "  FROM `{bq_helper.dataset_ref}.customers_standardized`\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  SELECT\n",
    "    'Records with Embeddings' as stage,\n",
    "    COUNT(*) as record_count\n",
    "  FROM `{bq_helper.dataset_ref}.customers_with_embeddings`\n",
    "  WHERE ml_generate_embedding_result IS NOT NULL\n",
    "\n",
    "  UNION ALL\n",
    "\n",
    "  SELECT\n",
    "    'Golden Records' as stage,\n",
    "    COUNT(*) as record_count\n",
    "  FROM `{bq_helper.dataset_ref}.golden_records`\n",
    ")\n",
    "SELECT * FROM stats ORDER BY record_count DESC\n",
    "\"\"\"\n",
    "\n",
    "overall_stats = bq_helper.execute_query(overall_stats_sql)\n",
    "print(\"\\nüìà Pipeline Statistics:\")\n",
    "display(overall_stats)\n",
    "\n",
    "# Visualize pipeline flow\n",
    "fig = px.funnel(\n",
    "    overall_stats,\n",
    "    x='record_count',\n",
    "    y='stage',\n",
    "    title='MDM Pipeline Data Flow',\n",
    "    labels={'record_count': 'Number of Records', 'stage': 'Pipeline Stage'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze 5-strategy matching effectiveness\n",
    "strategy_analysis_sql = f\"\"\"\n",
    "SELECT\n",
    "  'Exact Matching' as strategy,\n",
    "  COUNT(*) as matches_found,\n",
    "  AVG(exact_score) as avg_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "WHERE exact_score > 0\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'Fuzzy Matching' as strategy,\n",
    "  COUNT(*) as matches_found,\n",
    "  AVG(fuzzy_score) as avg_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "WHERE fuzzy_score > 0\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'Vector Matching' as strategy,\n",
    "  COUNT(*) as matches_found,\n",
    "  AVG(vector_score) as avg_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "WHERE vector_score > 0\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'Business Rules' as strategy,\n",
    "  COUNT(*) as matches_found,\n",
    "  AVG(business_score) as avg_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "WHERE business_score > 0\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  'AI Natural Language' as strategy,\n",
    "  COUNT(*) as matches_found,\n",
    "  AVG(ai_score) as avg_score\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "WHERE ai_score > 0\n",
    "\n",
    "ORDER BY matches_found DESC\n",
    "\"\"\"\n",
    "\n",
    "strategy_stats = bq_helper.execute_query(strategy_analysis_sql)\n",
    "print(\"\\nüéØ 5-Strategy Matching Effectiveness:\")\n",
    "display(strategy_stats)\n",
    "\n",
    "# Create visualization\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Matches Found by Strategy', 'Average Score by Strategy'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=strategy_stats['strategy'],\n",
    "           y=strategy_stats['matches_found'], name='Matches'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=strategy_stats['strategy'],\n",
    "           y=strategy_stats['avg_score'], name='Avg Score'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text=\"5-Strategy Matching Analysis\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confidence distribution\n",
    "confidence_dist_sql = f\"\"\"\n",
    "SELECT\n",
    "  ROUND(combined_score, 1) as score_bucket,\n",
    "  COUNT(*) as count,\n",
    "  match_decision\n",
    "FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    "GROUP BY score_bucket, match_decision\n",
    "ORDER BY score_bucket\n",
    "\"\"\"\n",
    "\n",
    "confidence_dist = bq_helper.execute_query(confidence_dist_sql)\n",
    "print(\"\\nüìä Confidence Score Distribution:\")\n",
    "display(confidence_dist.head(10))\n",
    "\n",
    "# Create confidence distribution plot\n",
    "fig = px.histogram(\n",
    "    confidence_dist,\n",
    "    x='score_bucket',\n",
    "    y='count',\n",
    "    color='match_decision',\n",
    "    title='Distribution of Match Confidence Scores (5-Strategy)',\n",
    "    labels={'score_bucket': 'Confidence Score', 'count': 'Number of Matches'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Metrics and Summary\n",
    "\n",
    "Calculate key performance indicators for the 5-strategy MDM pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "print(\"üìà Calculating 5-Strategy MDM Performance Metrics...\")\n",
    "\n",
    "# Data quality metrics\n",
    "quality_metrics_sql = f\"\"\"\n",
    "WITH quality_stats AS (\n",
    "  SELECT\n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(CASE WHEN email_clean IS NOT NULL THEN 1 END) / COUNT(*) as email_completeness,\n",
    "    COUNT(CASE WHEN phone_clean IS NOT NULL THEN 1 END) / COUNT(*) as phone_completeness,\n",
    "    COUNT(CASE WHEN address_clean IS NOT NULL THEN 1 END) / COUNT(*) as address_completeness,\n",
    "    COUNT(DISTINCT email_clean) / COUNT(CASE WHEN email_clean IS NOT NULL THEN 1 END) as email_uniqueness,\n",
    "    COUNT(DISTINCT phone_clean) / COUNT(CASE WHEN phone_clean IS NOT NULL THEN 1 END) as phone_uniqueness\n",
    "  FROM `{bq_helper.dataset_ref}.customers_standardized`\n",
    ")\n",
    "SELECT\n",
    "  total_records,\n",
    "  ROUND(email_completeness * 100, 2) as email_completeness_pct,\n",
    "  ROUND(phone_completeness * 100, 2) as phone_completeness_pct,\n",
    "  ROUND(address_completeness * 100, 2) as address_completeness_pct,\n",
    "  ROUND(email_uniqueness * 100, 2) as email_uniqueness_pct,\n",
    "  ROUND(phone_uniqueness * 100, 2) as phone_uniqueness_pct\n",
    "FROM quality_stats\n",
    "\"\"\"\n",
    "\n",
    "quality_metrics = bq_helper.execute_query(quality_metrics_sql)\n",
    "print(\"\\nüìä Data Quality Metrics:\")\n",
    "display(quality_metrics)\n",
    "\n",
    "# Matching effectiveness\n",
    "matching_metrics_sql = f\"\"\"\n",
    "WITH matching_stats AS (\n",
    "  SELECT\n",
    "    COUNT(*) as total_potential_matches,\n",
    "    COUNT(CASE WHEN match_decision = 'auto_merge' THEN 1 END) as auto_merge_count,\n",
    "    COUNT(CASE WHEN match_decision = 'human_review' THEN 1 END) as human_review_count,\n",
    "    COUNT(CASE WHEN match_decision = 'no_match' THEN 1 END) as no_match_count,\n",
    "    AVG(combined_score) as avg_combined_score\n",
    "  FROM `{bq_helper.dataset_ref}.customers_with_embeddings_combined_matches`\n",
    ")\n",
    "SELECT\n",
    "  total_potential_matches,\n",
    "  auto_merge_count,\n",
    "  human_review_count,\n",
    "  no_match_count,\n",
    "  ROUND(auto_merge_count / total_potential_matches * 100, 2) as auto_merge_rate_pct,\n",
    "  ROUND(human_review_count / total_potential_matches * 100, 2) as human_review_rate_pct,\n",
    "  ROUND(avg_combined_score, 3) as avg_combined_score\n",
    "FROM matching_stats\n",
    "\"\"\"\n",
    "\n",
    "matching_metrics = bq_helper.execute_query(matching_metrics_sql)\n",
    "print(\"\\nüéØ 5-Strategy Matching Effectiveness:\")\n",
    "display(matching_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ 5-STRATEGY MDM PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä DATA PROCESSING:\")\n",
    "print(\n",
    "    f\"  ‚Ä¢ Generated {total_records:,} sample records from {len(datasets)} sources\")\n",
    "print(f\"  ‚Ä¢ Representing {generator.num_unique_customers:,} unique customers\")\n",
    "print(\n",
    "    f\"  ‚Ä¢ Duplication factor: {total_records / generator.num_unique_customers:.2f}x\")\n",
    "\n",
    "if not quality_metrics.empty:\n",
    "    print(f\"\\nüìà DATA QUALITY:\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Email completeness: {quality_metrics.iloc[0]['email_completeness_pct']:.1f}%\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Phone completeness: {quality_metrics.iloc[0]['phone_completeness_pct']:.1f}%\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Address completeness: {quality_metrics.iloc[0]['address_completeness_pct']:.1f}%\")\n",
    "\n",
    "if not matching_metrics.empty:\n",
    "    print(f\"\\nüéØ 5-STRATEGY MATCHING RESULTS:\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Total potential matches: {matching_metrics.iloc[0]['total_potential_matches']:,}\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Auto-merge rate: {matching_metrics.iloc[0]['auto_merge_rate_pct']:.1f}%\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Human review rate: {matching_metrics.iloc[0]['human_review_rate_pct']:.1f}%\")\n",
    "    print(\n",
    "        f\"  ‚Ä¢ Average combined score: {matching_metrics.iloc[0]['avg_combined_score']:.3f}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è ENHANCED ARCHITECTURE HIGHLIGHTS:\")\n",
    "print(f\"  ‚Ä¢ 100% BigQuery-native implementation\")\n",
    "print(f\"  ‚Ä¢ Latest gemini-embedding-001 model for vector matching\")\n",
    "print(f\"  ‚Ä¢ NEW: Gemini 2.5 Pro for AI natural language matching\")\n",
    "print(f\"  ‚Ä¢ Vector indexes for fast similarity search\")\n",
    "print(f\"  ‚Ä¢ 5-strategy matching (exact, fuzzy, vector, rules, AI)\")\n",
    "print(f\"  ‚Ä¢ Enhanced weighted ensemble scoring\")\n",
    "print(f\"  ‚Ä¢ AI-powered explanations for match decisions\")\n",
    "print(f\"  ‚Ä¢ Automated confidence scoring and decision making\")\n",
    "print(f\"  ‚Ä¢ Survivorship rules for golden record creation\")\n",
    "\n",
    "print(f\"\\n‚úÖ 5-STRATEGY PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
